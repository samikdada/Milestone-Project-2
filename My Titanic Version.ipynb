{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import (AdaBoostClassifier,RandomForestClassifier,ExtraTreesClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = [train_df, test_df]\n",
    "Passenger_Id_train = train_df['PassengerId']\n",
    "Passenger_Id_test = test_df['PassengerId']\n",
    "train_df.drop(['PassengerId'], axis=1, inplace=True)\n",
    "test_df.drop(['PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode(), inplace= True)\n",
    "    dataset['Has_Cabin'] = dataset['Cabin'].apply(lambda x : 0 if type(x) == float else 1)\n",
    "    dataset['Family_Size'] = dataset['Parch'] + dataset['SibSp'] + 1\n",
    "    dataset['Is_Alone'] = dataset['Family_Size'].apply(lambda x: 1 if x == 1 else 0)    \n",
    "    dataset.drop(['Cabin', 'Ticket'], inplace=True, axis=1)\n",
    "    \n",
    "#Dividing the Age and the Fare column into Numerical Categories\n",
    "    dataset['Age'].fillna(dataset['Age'].mean(),inplace = True)\n",
    "    dataset['Categorical_Age'] = pd.cut(dataset['Age'],5)\n",
    "    \n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "    dataset['Categorical_Fare'] = pd.cut(dataset['Fare'], 4)\n",
    "    \n",
    "    dataset.loc[(dataset['Fare']< 128.082), 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] >=128.082) & (dataset['Fare']< 256.165), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] >=256.165) & (dataset['Fare']< 384.247), 'Fare'] = 2\n",
    "    dataset.loc[(dataset['Fare'] >=384.247) & (dataset['Fare']< 513), 'Fare'] = 3   \n",
    "    dataset.loc[(dataset['Age']< 16.336), 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] >=16.336) & (dataset['Age']< 32.252), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] >=32.252) & (dataset['Age']< 48.168), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] >=48.168) & (dataset['Age']< 64.084), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] >=64.084) & (dataset['Age']< 81), 'Age'] = 4\n",
    "    dataset.drop(['Categorical_Age', \"Categorical_Fare\"], axis= 1, inplace= True)\n",
    "    \n",
    "#Extracting the different titles from Name column  \n",
    "    Name = dataset['Name']\n",
    "    Name = Name.apply(str.split, args=('.'))\n",
    "    title = [i.split(',')[1] for i in [i[0] for i in Name]]\n",
    "    dataset['Title'] = title\n",
    "    salDict = {' Mr' : 1, ' Mrs' :2 , ' Miss' :2 , ' Master' : 1, ' Don' :4 , ' Rev' :4 , ' Dr' :4 , ' Mme' :4,\n",
    "       ' Ms' :2 , ' Major' :3 , ' Lady' :2 , ' Sir' :1 , ' Mlle' :4 , ' Col' :3 , ' Capt' :3 , \n",
    "       ' the Countess' :2 , ' Jonkheer': 4, ' Dona' : 4}\n",
    "    dataset['Title'].replace(salDict, inplace=True)\n",
    "    dataset.drop(['Name'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df,columns=['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'Has_Cabin', 'Is_Alone'], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df,columns=['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'Has_Cabin', 'Is_Alone'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnHelper():\n",
    "    \n",
    "    def __init__(self, clf, params=None):\n",
    "        self.clf = clf(**params)\n",
    "        \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_split = 5\n",
    "kfold = KFold(n_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oof_Cal(clf, x_train, y_train, test_df):\n",
    "    n_split = 5\n",
    "    oof_train = np.zeros(x_train.shape[0],)\n",
    "    oof_test = np.zeros(test_df.shape[0],)\n",
    "    oof_test_svf = np.empty((n_split, test_df.shape[0]))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(x_train)):\n",
    "        \n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "    \n",
    "        clf.fit(x_tr, y_tr)\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_svf[i, :] =  clf.predict(test_df)\n",
    "        oof_test = oof_test_svf.mean(axis=0)\n",
    "        \n",
    "    return oof_train.reshape(-1,1), oof_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop('Survived', axis= True).values\n",
    "y_train = train_df['Survived'].values\n",
    "x_test = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = SklearnHelper(AdaBoostClassifier, ada_params)\n",
    "rf = SklearnHelper(RandomForestClassifier, rf_params)\n",
    "et = SklearnHelper(ExtraTreesClassifier, et_params)\n",
    "gb = SklearnHelper(GradientBoostingClassifier, gb_params)\n",
    "sv = SklearnHelper(SVC, svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e5565890\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:305: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    }
   ],
   "source": [
    "adb_oof_train, adb_oof_test = oof_Cal(adb, x_train, y_train, x_test)\n",
    "rf_oof_train, rf_oof_test = oof_Cal(rf, x_train, y_train, x_test)\n",
    "et_oof_train, et_oof_test = oof_Cal(et, x_train, y_train, x_test)\n",
    "gb_oof_train, gb_oof_test = oof_Cal(gb, x_train, y_train, x_test)\n",
    "sv_oof_train, sv_oof_test = oof_Cal(sv, x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([adb_oof_train, rf_oof_train, et_oof_train, gb_oof_train, sv_oof_train], axis=1)\n",
    "x_test = np.concatenate([adb_oof_test, rf_oof_test, et_oof_test, gb_oof_test, sv_oof_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (xgboost.dll) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libgomp.so for UNIX-like OSes)\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['[WinError 5] Access is denied']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-3866fcdef3cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;31m# load the XGBoost library globally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m \u001b[0m_LIB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[1;34m()\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;34m'libgomp.so for UNIX-like OSes)\\n'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[1;34m'  * You are running 32-bit Python on a 64-bit OS\\n'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m             'Error message(s): {}\\n'.format(os_error_list))\n\u001b[0m\u001b[0;32m    155\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: XGBoost Library (xgboost.dll) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libgomp.so for UNIX-like OSes)\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['[WinError 5] Access is denied']\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
