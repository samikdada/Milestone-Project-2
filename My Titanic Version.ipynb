{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import (AdaBoostClassifier,RandomForestClassifier,ExtraTreesClassifier,\n",
    "                              GradientBoostingClassifier, BaggingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = [train_df, test_df]\n",
    "Passenger_Id_train = train_df['PassengerId']\n",
    "Passenger_Id_test = test_df['PassengerId']\n",
    "train_df.drop(['PassengerId'], axis=1, inplace=True)\n",
    "test_df.drop(['PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Embarked'].fillna('S', inplace= True)\n",
    "    dataset['Has_Cabin'] = dataset['Cabin'].apply(lambda x : 0 if type(x) == float else 1)\n",
    "    dataset['Family_Size'] = dataset['Parch'] + dataset['SibSp'] + 1\n",
    "    dataset['Is_Alone'] = dataset['Family_Size'].apply(lambda x: 1 if x == 1 else 0)    \n",
    "    dataset.drop(['Cabin', 'Ticket'], inplace=True, axis=1)\n",
    "    \n",
    "    #Dividing the Age and the Fare column into Numerical Categories\n",
    "    dataset['Age'].fillna(dataset['Age'].mean(),inplace = True)\n",
    "    dataset['Categorical_Age'] = pd.cut(dataset['Age'],5)\n",
    "    \n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "    dataset['Categorical_Fare'] = pd.cut(dataset['Fare'], 4)\n",
    "    \n",
    "    dataset.loc[(dataset['Fare']< 128.082), 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] >=128.082) & (dataset['Fare']< 256.165), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] >=256.165) & (dataset['Fare']< 384.247), 'Fare'] = 2\n",
    "    dataset.loc[(dataset['Fare'] >=384.247) & (dataset['Fare']< 513), 'Fare'] = 3   \n",
    "    dataset.loc[(dataset['Age']< 16.336), 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] >=16.336) & (dataset['Age']< 32.252), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] >=32.252) & (dataset['Age']< 48.168), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] >=48.168) & (dataset['Age']< 64.084), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] >=64.084) & (dataset['Age']< 81), 'Age'] = 4\n",
    "    dataset.drop(['Categorical_Age', \"Categorical_Fare\"], axis= 1, inplace= True)\n",
    "    \n",
    "    \n",
    "    #Extracting the different titles from Name column and assigning categories to them\n",
    "\n",
    "    saldict = {1: [' Mr', ' Master', ' Don', ' Sir'], 2: [' Mrs', ' Miss', ' Ms', ' Lady', ' the Countess'], \n",
    "                3: [' Dr', ' Major', ' Col', ' Capt',]}\n",
    "\n",
    "    dataset['Title'] = [i.split(',')[1] for i in [i[0] for i in dataset['Name'].apply(str.split, args=('.'))]]\n",
    "    for title, index in zip(dataset['Title'].values, np.arange(len(dataset['Title']))):\n",
    "        for (key, value) in saldict.items():\n",
    "            if title in value:\n",
    "                dataset['Title'][index] = key\n",
    "                break\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].apply(lambda x: 4 if type(x) == str else x)\n",
    "    dataset.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df,columns=['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title'], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df,columns=['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop('Survived', axis= True).values\n",
    "y_train = train_df['Survived'].values\n",
    "x_test = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': [-1],\n",
    "    'n_estimators': [500, 600, 700, 800, 900],\n",
    "    'warm_start': [True],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'max_features' : ['sqrt', 'log2'],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "bc_params = {\n",
    "    'n_estimators': [900, 1000,1200, 1300, 1500],\n",
    "    'warm_start': [True],\n",
    "    'max_samples': [6, 7, 8, 9, 10],\n",
    "    'verbose': [0],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "adb_params = {\n",
    "    'n_estimators': [300, 400, 500, 550, 600, 650, 700, 800],\n",
    "    'learning_rate' : [0.3, 0.4, 0.5, 0.75]\n",
    "}\n",
    "\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : ['linear', 'poly', 'rbf'],\n",
    "    'C' : [0.025, 0.25, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    }\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': [-1],\n",
    "    'n_estimators':[500, 600, 700, 800, 900],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': [500, 600, 700, 800, 900],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'verbose': [0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnHelper():\n",
    "    \n",
    "    def __init__(self, clf, name,  x_train, y_train, param_grid= None):\n",
    "        \n",
    "        if param_grid == None:\n",
    "            self.clf = clf()\n",
    "            accuracy_scores = cross_val_score(self.clf, X= x_train, y= y_train, cv = 10, n_jobs= -1)\n",
    "            print(name + '->', accuracy_scores.mean())\n",
    "        else:\n",
    "            grid = GridSearchCV(clf(), scoring= 'accuracy', cv=10, param_grid= param_grid, n_jobs= -1)\n",
    "            grid.fit(x_train, y_train)\n",
    "            print(name + '->', grid.best_score_, grid.best_params_)\n",
    "            self.clf = clf(**grid.best_params_)\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        return self.clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_split = 5\n",
    "kfold = KFold(n_split)\n",
    "\n",
    "def oof_Cal(clf, x_train, y_train, test_df):\n",
    "    n_split = 5\n",
    "    oof_train = np.zeros(x_train.shape[0],)\n",
    "    oof_test = np.zeros(test_df.shape[0],)\n",
    "    oof_test_svf = np.empty((n_split, test_df.shape[0]))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(x_train)):\n",
    "        \n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "    \n",
    "        clf.fit(x_tr, y_tr)\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_svf[i, :] =  clf.predict(test_df)\n",
    "        oof_test = oof_test_svf.mean(axis=0)\n",
    "        \n",
    "    return oof_train.reshape(-1,1), oof_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging-> 0.792368125701459 {'max_samples': 7, 'n_estimators': 1000, 'n_jobs': -1, 'verbose': 0, 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "adb = SklearnHelper(AdaBoostClassifier, 'Ada Boost' , x_train, y_train, adb_params)\n",
    "rf = SklearnHelper(RandomForestClassifier, 'Random Forest' , x_train, y_train, rf_params)\n",
    "et = SklearnHelper(ExtraTreesClassifier, 'Extra Tree' , x_train, y_train, et_params)\n",
    "gb = SklearnHelper(GradientBoostingClassifier, 'Gradient Boost' , x_train, y_train, gb_params)\n",
    "bc = SklearnHelper(BaggingClassifier, 'Bagging', x_train, y_train, bc_params)\n",
    "sv = SklearnHelper(SVC, 'SVC', x_train, y_train, svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samik Biswas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:305: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    }
   ],
   "source": [
    "adb_oof_train, adb_oof_test = oof_Cal(adb, x_train, y_train, x_test)\n",
    "rf_oof_train, rf_oof_test = oof_Cal(rf, x_train, y_train, x_test)\n",
    "et_oof_train, et_oof_test = oof_Cal(et, x_train, y_train, x_test)\n",
    "gb_oof_train, gb_oof_test = oof_Cal(gb, x_train, y_train, x_test)\n",
    "bc_oof_train, bc_oof_test = oof_Cal(bc, x_train, y_train, x_test)\n",
    "sv_oof_train, sv_oof_test = oof_Cal(sv, x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([adb_oof_train, rf_oof_train, et_oof_train, gb_oof_train, sv_oof_train], axis=1)\n",
    "x_test = np.concatenate([adb_oof_test, rf_oof_test, et_oof_test, gb_oof_test, sv_oof_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_params = {'learning_rate' : [0.02, 0.3, 0.4, 0.5, 0.6, 0,8, 1, 1.2, 1.3],\n",
    "             'n_estimators': [1000, 2000, 3000, 4000, 5000, 6000],\n",
    "             'max_depth': [2,3,4,5,6,7,8],\n",
    "             'min_child_weight': [2,3,4,5,6,7],\n",
    "             'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0 , 1.1, 1.2, 1.3, 1.4],                        \n",
    "             'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0 , 1.1, 1.2, 1.3, 1.4],\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0 , 1.1, 1.2, 1.3, 1.4],\n",
    "             'objective': ['binary:logistic'],\n",
    "             'nthread': [-1],\n",
    "             'scale_pos_weight': [1]}\n",
    "\n",
    "#grid = GridSearchCV(XGBClassifier(), scoring= 'accuracy', cv=10, param_grid= xg_params, n_jobs= -1)\n",
    "xg = SklearnHelper(XGBClassifier, 'XG', x_train, y_train, xg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.9, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=4, min_child_weight=2, missing=None,\n",
       "       n_estimators=2000, n_jobs=1, nthread=-1,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = DataFrame(Passenger_Id_test.ravel(), xg.predict(x_test).ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
